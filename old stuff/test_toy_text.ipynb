{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX devices:[cuda(id=0), cuda(id=1), cuda(id=2)]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import optax\n",
    "import flax\n",
    "from flax.training.train_state import TrainState\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n",
    "from dataset.toytext import TextDataset\n",
    "from models.language import BigramLM, TransormerLM, MambaLM\n",
    "import training\n",
    "\n",
    "print(f\"JAX devices:{jax.devices()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = jax.random.key(0)\n",
    "max_context_len = 64\n",
    "batch_size = 64\n",
    "\n",
    "dataset = TextDataset(data_path=\"dataset/shakespeare.txt\")\n",
    "# model = MambaLM(\n",
    "#     vocab_size=len(dataset.tokenizer.vocab),\n",
    "#     max_context_len=max_context_len,\n",
    "#     embedding_dim=64,\n",
    "#     state_dim=64,\n",
    "#     n_layers=4\n",
    "# )\n",
    "model= TransormerLM(\n",
    "    vocab_size=len(dataset.tokenizer.vocab),\n",
    "    max_context_len=max_context_len,\n",
    "    embedding_dim=64,\n",
    "    head_size=128,\n",
    "    n_heads=4,\n",
    "    n_layers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64)\n",
      "(64, 128)\n",
      "(64, 64)\n",
      "(64, 128)\n",
      "(64, 64)\n",
      "(64, 128)\n",
      "(64, 64)\n",
      "(64, 128)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b6e7c152a14b4db8fe7872a18b4fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5310ec2612564d00bedf8c72e6a570ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64)\n",
      "(64, 128)\n",
      "(64, 64)\n",
      "(64, 128)\n",
      "(64, 64)\n",
      "(64, 128)\n",
      "(64, 64)\n",
      "(64, 128)\n",
      "Loss: 1.9618247747421265\n",
      "Generation test:\n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "Al \u001b[0m(64, 64)\n",
      "(64, 128)\n",
      "(64, 64)\n",
      "(64, 128)\n",
      "(64, 64)\n",
      "(64, 128)\n",
      "(64, 64)\n",
      "(64, 128)\n",
      "onVenMENIUS:\n",
      "He's name too: let I say.\n",
      "\n",
      "GLOUCESTER:\n",
      "Mamently actiong by:\n",
      "Mother sase that At:\n",
      "Noward father, conscepar here: of Sread,\n",
      "Wells twones in swort what I will a houldring\n",
      "I had to pastings, if the madaricusance, Lord, an I'll York.\n",
      "\n",
      "MENENIUS:\n",
      "If Gaulness your ceread fortweelling in the.\n",
      "\n",
      "VOLUMNIA:\n",
      "A lovestreess, so is concle, to, this brown eame,\n",
      "Their counselt dissoom o' so queedins:\n",
      "Then He serval not those yourseld?\n",
      "Of givellassaly the sisidea, old that Jrows that them,\n",
      "Apoused of t"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0204472f544658a8730b3c564d47cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5007067918777466\n",
      "Generation test:\n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "Al \u001b[0ml.\n",
      "\n",
      "AMPttructimagenatior:\n",
      "Pething these banishment, that blantary to be:\n",
      "Mont?\n",
      "\n",
      "WARWIBANUS:\n",
      "What are naether, sir, Hasting thou Scall,\n",
      "Welrs two much me he, whose like law orlazine\n",
      "To Nabout? seize did:\n",
      "Lucent hith on your facter, I'll burniag,\n",
      "When them that never firm erecul, dew there?\n",
      "\n",
      "JULIET:\n",
      "Brathear thing:--\n",
      "The deason!\n",
      "What morrow, this body feast, I time you?\n",
      "\n",
      "SETSCLIUS:\n",
      "'Tis queen held never the most trial speak leave?\n",
      "O poison, what is so! Mistory live a wart son;\n",
      "As ever'd me father,"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9714079ffbb45f0a325067fa2157a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4290919303894043\n",
      "Generation test:\n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "Al \u001b[0ml:\n",
      "A Margaret's worthy tyrant, mating Kate:\n",
      "Bost of that bland, conpedity, to bases\n",
      "That ill:\n",
      "Now then e'er then we art well, forced his prevent\n",
      "But keep it what I will all, by so remains;\n",
      "Then in evil: whils murdelo your Lucate;\n",
      "A serve whiar, go be the tiallo.\n",
      "\n",
      "PARIS:\n",
      "Do our pake that a winter.\n",
      "\n",
      "BUCKINGHAM:\n",
      "Sweet when ever is your marke, that be.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Ne'er shallo's motherer; pay this want.\n",
      ". Then Edward is it is spide my charrity:\n",
      "Ay, death live a wart son; you have put for amo"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31789fecc394a7f81a5922c31613d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3917101621627808\n",
      "Generation test:\n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "Al \u001b[0ml:\n",
      "Ay, to joy my fats I,\n",
      "I fear at as call in success' entland,\n",
      "As prike to in as seitir, At:\n",
      "I came not; and so we ablock the berviness,\n",
      "Is two much merry, why the shelance of so reshookes\n",
      "Bestides, if the mattricloanly follate;\n",
      "A couck-ancaed in be the time nexcuted him,\n",
      "Ado sake the baging of her.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Bushy Kates me, to-morrow:\n",
      "Not promisesting hateful dispositions?\n",
      "Go kerhop your lives mo.\n",
      "\n",
      "JADIEL:\n",
      "I\n",
      "OF Jupitation, let that is: I must course\n",
      "With Jrine the underfordows darkme"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94153d45d14c4db3a6da1de1390d740c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3665975332260132\n",
      "Generation test:\n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "Al \u001b[0ml.\n",
      "\n",
      "All:\n",
      "Well, thy as I'll:\n",
      "They that Keepere straited entle; a city bistooping.\n",
      "\n",
      "FEither:\n",
      "Nor is the neglect she ways destite become,\n",
      "Wells two such merriment in like law or,\n",
      "Is not hope of their edicts; from his done,\n",
      "You accept the county his flesh empts upon cousin ceremony;\n",
      "But an in in the kin.\n",
      "\n",
      "HENRY BOLINGBROKEE:\n",
      "My lord, tranio were such deny.\n",
      "\n",
      "NORTNUS:\n",
      "What, thou art off's meque drinks not of them;.\n",
      "\n",
      "JAD ELIZANO:\n",
      "You art again, were Lancans?\n",
      "\n",
      "BIONA:\n",
      "Madam wart so wilt be:\n",
      "Thou seek kno"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9fa9325e8045919e38fc32f20733fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3486390113830566\n",
      "Generation test:\n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "Al \u001b[0mone,\n",
      "My presention as I'll fly, I saw Kate:\n",
      "Most castage, language prince, pion! gentle wilt:\n",
      "If an you grant so we abatch the bereal,\n",
      "Well known my ken hears, in life laws,\n",
      "The kind hath slaspting did I; from hither wish.\n",
      "Folk, give you why hang, but her sault.\n",
      "My form ere do sake the japen's. The king dreams,\n",
      "You when the field transpare; and to whom my outting,\n",
      "Thereto tash as 's not breathed in the rest\n",
      ".\n",
      "\n",
      "JALIEN:\n",
      "Inful mad?\n",
      "O pilbot, what is such is as thy lane,\n",
      "Chastist up thy courses ofts"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0f88ba60dc4ad8be6a227898db7e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.332741379737854\n",
      "Generation test:\n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "Al \u001b[0ml.\n",
      "\n",
      "HORTENSIO:\n",
      "Here, what? Come, that Kate herself, come, lang, conpedit\n",
      "on in as seithe is to-morrow? while conscience,\n",
      "That falcon ricely known drinks her whose.\n",
      "When a horse so remainst to sting did:\n",
      "Lucion hith on your face, give his whiah,\n",
      "When we must unnexcors in enemies;\n",
      "For all apinhour heart with thine:--\n",
      "The devil is your mark,--this book her king:\n",
      "Here shere but my moo's moquerering silk!\n",
      "A remain night! so your mad?\n",
      "O polight, if with us? is a king, an alreasons out\n",
      "The counsel of t"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c41bf57034c4624a074bfbdd7dc705a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3209737539291382\n",
      "Generation test:\n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "Al \u001b[0ml.\n",
      "\n",
      "All TYRREL:\n",
      "What, I, is, home, as King on Nicatio's holy;\n",
      "And buy with theirs; nither Antigonus bear\n",
      "For mone banished the Spreak, colds two\n",
      "much merrit what I will awhile: so resolution?\n",
      "Anies didst us my head.\n",
      "And thou conceit'st on him, else\n",
      "That resageneration hath of Pod:\n",
      "It is a joy so.\n",
      "\n",
      "VOLUMNIA:\n",
      "Hie me, my God-solicy: trumpet,--this begin!\n",
      "Zok, I tinken thee be jealous' sold bedrience from the ro.\n",
      "\n",
      "JULIET:\n",
      "I firmed into his mother, in succession of my ajest.\n",
      "This sun I have heard kno"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5256c758bd2448f8ad659c8401388a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3092433214187622\n",
      "Generation test:\n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "Al \u001b[0ml.\n",
      "\n",
      "AMPEY:\n",
      "Commend an unseason, I say.\n",
      "\n",
      "LUCENTIO:\n",
      "\n",
      "CLAUDIO:\n",
      "Have it know their chases.\n",
      "\n",
      "Pier:\n",
      "I can be the reconcile bad me to be with\n",
      "colds two much enjoin what I will away of so remains\n",
      "From time did I unform'd.\n",
      "\n",
      "ANGELO:\n",
      "Face with vice whial,\n",
      "When we must prove our face, of Irelened with\n",
      "My kind truth from her:--\n",
      "The deast is betray'd with such one earl.\n",
      "\n",
      "Third SERT:\n",
      "So far how 'tis queed here is no wretch.\n",
      "\n",
      "JULIET:\n",
      "I fell the that we lack or husband, and there\n",
      "Unlest somewhile my course, or h"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf74dd804354918a2275df227906dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimization_step = jax.jit(\n",
    "    partial(training.optimization_step, loss_fn=training.logit_prediction_loss)\n",
    ")\n",
    "get_batch = jax.jit(dataset.get_batch, static_argnames=[\"batch_size\", \"context_len\"])\n",
    "generate_token = jax.jit(partial(model.apply, method=model.generate_token))\n",
    "\n",
    "def generate_text(params, prompt: str, length=500, rng_key=jax.random.key(0)):\n",
    "    context = dataset.tokenizer.encode(prompt)\n",
    "    print(\"\\033[94m\", dataset.tokenizer.decode(context), \"\\033[0m\", end=\"\")\n",
    "    for sub_rng in jax.random.split(rng_key, length):\n",
    "        next_token, context = generate_token(params, context, sub_rng)\n",
    "        print(dataset.tokenizer.decode(next_token[None]), end=\"\")\n",
    "\n",
    "\n",
    "train_state = TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=model.init(rng_key, dataset.sample(max_context_len, rng_key)),\n",
    "    tx=optax.chain(optax.clip(1.0), optax.adam(3e-3, b2=0.95)),\n",
    ")\n",
    "\n",
    "N_epochs = 10\n",
    "batches_per_epoch = 1000\n",
    "for epoch_idx, epoch_rng_key in enumerate(tqdm(jax.random.split(rng_key, N_epochs))):\n",
    "    losses = []\n",
    "    for batch_rng_key in tqdm(jax.random.split(epoch_rng_key, batches_per_epoch), leave=False):\n",
    "        x, y = get_batch(batch_size, max_context_len, rng_key=batch_rng_key)\n",
    "        train_state, loss_value = optimization_step(train_state, x, y)\n",
    "        losses.append(loss_value)\n",
    "    print(f\"Loss: {sum(losses) / len(losses)}\\nGeneration test:\")\n",
    "    generate_text(train_state.params, prompt=dataset.fulltext[:max_context_len], rng_key=rng_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
